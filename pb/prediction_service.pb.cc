// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: prediction_service.proto

#include "prediction_service.pb.h"

#include <algorithm>

#include <google/protobuf/io/coded_stream.h>
#include <google/protobuf/extension_set.h>
#include <google/protobuf/wire_format_lite.h>
#include <google/protobuf/descriptor.h>
#include <google/protobuf/generated_message_reflection.h>
#include <google/protobuf/reflection_ops.h>
#include <google/protobuf/wire_format.h>
// @@protoc_insertion_point(includes)
#include <google/protobuf/port_def.inc>

PROTOBUF_PRAGMA_INIT_SEG
namespace tensorflow {
namespace serving {
}  // namespace serving
}  // namespace tensorflow
static constexpr ::PROTOBUF_NAMESPACE_ID::Metadata* file_level_metadata_prediction_5fservice_2eproto = nullptr;
static constexpr ::PROTOBUF_NAMESPACE_ID::EnumDescriptor const** file_level_enum_descriptors_prediction_5fservice_2eproto = nullptr;
static constexpr ::PROTOBUF_NAMESPACE_ID::ServiceDescriptor const** file_level_service_descriptors_prediction_5fservice_2eproto = nullptr;
const ::PROTOBUF_NAMESPACE_ID::uint32 TableStruct_prediction_5fservice_2eproto::offsets[1] = {};
static constexpr ::PROTOBUF_NAMESPACE_ID::internal::MigrationSchema* schemas = nullptr;
static constexpr ::PROTOBUF_NAMESPACE_ID::Message* const* file_default_instances = nullptr;

const char descriptor_table_protodef_prediction_5fservice_2eproto[] PROTOBUF_SECTION_VARIABLE(protodesc_cold) =
  "\n\030prediction_service.proto\022\022tensorflow.s"
  "erving\032\rpredict.proto2g\n\021PredictionServi"
  "ce\022R\n\007Predict\022\".tensorflow.serving.Predi"
  "ctRequest\032#.tensorflow.serving.PredictRe"
  "sponseB\003\370\001\001b\006proto3"
  ;
static const ::PROTOBUF_NAMESPACE_ID::internal::DescriptorTable*const descriptor_table_prediction_5fservice_2eproto_deps[1] = {
  &::descriptor_table_predict_2eproto,
};
static ::PROTOBUF_NAMESPACE_ID::internal::once_flag descriptor_table_prediction_5fservice_2eproto_once;
const ::PROTOBUF_NAMESPACE_ID::internal::DescriptorTable descriptor_table_prediction_5fservice_2eproto = {
  false, false, 179, descriptor_table_protodef_prediction_5fservice_2eproto, "prediction_service.proto", 
  &descriptor_table_prediction_5fservice_2eproto_once, descriptor_table_prediction_5fservice_2eproto_deps, 1, 0,
  schemas, file_default_instances, TableStruct_prediction_5fservice_2eproto::offsets,
  file_level_metadata_prediction_5fservice_2eproto, file_level_enum_descriptors_prediction_5fservice_2eproto, file_level_service_descriptors_prediction_5fservice_2eproto,
};
PROTOBUF_ATTRIBUTE_WEAK ::PROTOBUF_NAMESPACE_ID::Metadata
descriptor_table_prediction_5fservice_2eproto_metadata_getter(int index) {
  ::PROTOBUF_NAMESPACE_ID::internal::AssignDescriptors(&descriptor_table_prediction_5fservice_2eproto);
  return descriptor_table_prediction_5fservice_2eproto.file_level_metadata[index];
}

// Force running AddDescriptors() at dynamic initialization time.
PROTOBUF_ATTRIBUTE_INIT_PRIORITY static ::PROTOBUF_NAMESPACE_ID::internal::AddDescriptorsRunner dynamic_init_dummy_prediction_5fservice_2eproto(&descriptor_table_prediction_5fservice_2eproto);
namespace tensorflow {
namespace serving {

// @@protoc_insertion_point(namespace_scope)
}  // namespace serving
}  // namespace tensorflow
PROTOBUF_NAMESPACE_OPEN
PROTOBUF_NAMESPACE_CLOSE

// @@protoc_insertion_point(global_scope)
#include <google/protobuf/port_undef.inc>
